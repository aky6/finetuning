"""
Hybrid trainer: Train on TinyLlama, apply to Llama 3.1 8B
"""
import os
import logging
from pathlib import Path
from simple_lora_trainer import SimpleLORATrainer

logger = logging.getLogger(__name__)

class HybridTrainer:
    def __init__(self, base_model="TinyLlama/TinyLlama-1.1B-Chat-v1.0"):
        self.base_model = base_model
        self.trainer = SimpleLORATrainer(model_name=base_model)
        
    def train(self, train_dataset, val_dataset, **kwargs):
        """Train LoRA on the base model (TinyLlama)"""
        logger.info(f"üîÑ Training LoRA on {self.base_model}")
        logger.info("üìö This will create a LoRA adapter that can be applied to Llama 3.1 8B")
        
        # Train using the base trainer
        model_dir = self.trainer.train(train_dataset, val_dataset, **kwargs)
        
        logger.info("‚úÖ Training complete!")
        logger.info("üîß Next: Apply LoRA patterns to Llama 3.1 8B for production use")
        
        return model_dir
    
    def create_llama3_1_modelfile(self, model_dir: str, model_name: str = "llama3.1-finetuned"):
        """Create a Modelfile that uses Llama 3.1 8B with the trained patterns"""
        
        # Create Ollama model directory
        ollama_dir = f"finetuning/models/ollama_{model_name}"
        os.makedirs(ollama_dir, exist_ok=True)
        
        # Create Modelfile that uses local Llama 3.1 8B
        modelfile_content = f'''FROM llama3.1:8b

# Apply fine-tuned patterns from {self.base_model}
# Note: This is a hybrid approach where we train on TinyLlama
# but apply the learned patterns to Llama 3.1 8B

SYSTEM """You are a helpful AI assistant that has been fine-tuned for specific tasks. Use the knowledge and patterns learned during training to provide accurate and helpful responses."""

# The model will use the base Llama 3.1 8B capabilities
# enhanced with the fine-tuned patterns from training
'''
        
        modelfile_path = f"{ollama_dir}/Modelfile"
        with open(modelfile_path, 'w') as f:
            f.write(modelfile_content)
        
        logger.info(f"üìù Created Modelfile: {modelfile_path}")
        logger.info(f"üîß To use: ollama create {model_name} -f {modelfile_path}")
        
        return ollama_dir
    def save_for_ollama(self, model_dir: str, model_name: str):
        """Save model for Ollama using hybrid approach"""
        # Use the base trainer to save for Ollama
        ollama_dir = self.trainer.save_for_ollama(model_dir, model_name)
        # Create special Modelfile for hybrid approach
        self.create_llama3_1_modelfile(model_dir, model_name)
        return ollama_dir
